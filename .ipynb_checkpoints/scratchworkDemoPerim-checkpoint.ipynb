{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d23f76ae",
   "metadata": {},
   "source": [
    "## Interactive Demo/Outputs for finalPerimsVsInteragency Py script\n",
    "- Interactive printing for finalized py script\n",
    "- Not a scratchwork zone; see `NIFCscratchwork` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b74fef15",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'finalized_perims' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# try: fetch manually the nifc williams incident\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# plot against identified fire lines\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m manual_find \u001b[38;5;241m=\u001b[39m \u001b[43mfinalized_perims\u001b[49m[finalized_perims\u001b[38;5;241m.\u001b[39mINCIDENT \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWilliams Flats\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mhead()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(manual_find)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmanual_find\u001b[38;5;241m.\u001b[39miloc[[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mDATE_CUR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'finalized_perims' is not defined"
     ]
    }
   ],
   "source": [
    "# try: fetch manually the nifc williams incident\n",
    "# plot against identified fire lines\n",
    "manual_find = finalized_perims[finalized_perims.INCIDENT == \"Williams Flats\"].head()\n",
    "# print(manual_find)\n",
    "print(f'date: {manual_find.iloc[[0]].DATE_CUR}')\n",
    "ax = manual_find.plot(facecolor=\"yellow\", edgecolor=\"black\", legend=True)\n",
    "\n",
    "ax_fidd_time = True\n",
    "\n",
    "for instance in range(finalized_williams.shape[0]):\n",
    "    print(f'william inst date, see if its a time issue: {finalized_williams.iloc[[instance]].t}')\n",
    "    finalized_williams.iloc[[instance]].plot(facecolor=\"orange\", edgecolor=\"black\", ax=ax)\n",
    "    # calculate intersect\n",
    "    resulting = gpd.overlay(manual_find,finalized_williams.iloc[[instance]], how='intersection')\n",
    "    if ax_fidd_time:\n",
    "        axy_new = resulting.plot(facecolor=\"red\", edgecolor=\"black\")\n",
    "        ax_fidd_time = False\n",
    "    else:\n",
    "        resulting.plot(facecolor=\"red\", edgecolor=\"black\", ax=axy_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "229a743a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BENCHMARKING: EVOLVING FIRE PERIM V. MODE\n",
      "Attempting set_crs (nifc)...\n",
      "Attempting set_crs (FEDS)...\n",
      "WARNING: No year extracted from FEDS output. Setting to None. No year reduction applied.\n",
      "VERBOSE DEBUG: DATE NOT NONE PRINT\n",
      "0        True\n",
      "1        True\n",
      "2        True\n",
      "3        True\n",
      "4        True\n",
      "         ... \n",
      "24742    True\n",
      "24743    True\n",
      "24744    True\n",
      "24745    True\n",
      "24746    True\n",
      "Length: 24745, dtype: bool\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/projects/env-feds/lib/python3.10/site-packages/geopandas/geodataframe.py:1472: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/projects/env-feds/lib/python3.10/site-packages/geopandas/geodataframe.py:1472: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per FEDS output, identify best NIFC match...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERBOSE: print find_nearest variables:\n",
      "date value of william\n",
      "2019-08-14 00:00:00\n",
      "best value matches/mins by distance\n",
      "2019-08-10 00:00:00\n",
      "finalized set from min res\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       OBJECTID              MAP_METHOD  DATE_CUR  \\\n",
      "395         396    Image Interpretation  20190810   \n",
      "396         397  Remote Sensing Derived  20190810   \n",
      "18829     18830                    None  20190810   \n",
      "\n",
      "                                                COMMENTS GEO_ID  \\\n",
      "395    Perimeter updated using Sentinel-2 Image Servi...    396   \n",
      "396    Perimeter digitized using Sentinel 2 image col...    397   \n",
      "18829  Engine 2462 discovered an old roadside fire, c...   1726   \n",
      "\n",
      "                                      IRWINID         UNQE_FIRE_ FIRE_YEAR  \\\n",
      "395    {8348636A-BC59-43B8-BCA8-E620847A948F}  2019-AKUYD-000217      2019   \n",
      "396    {C73013C8-BEBD-4465-8999-D75E34E7D55D}  2019-AKGAD-000614      2019   \n",
      "18829                                    None    2019-TXLGR-2053      2019   \n",
      "\n",
      "      LOCAL_NUM       INCIDENT UNIT_ID POO_RESP_I                FEATURE_CA  \\\n",
      "395      000217  Yukon Charley   AKYCP      AKUYD  Wildfire Final Perimeter   \n",
      "396      000614  Norutak Hills   AKGAP      AKGAD  Wildfire Final Perimeter   \n",
      "18829      2053     WALLER N/O   TXLGR       None                  Wildfire   \n",
      "\n",
      "       GIS_ACRES USER_NAME SOURCE AGENCY  FIRE_YEAR_    Shape__Are  \\\n",
      "395       3219.4      None   AICC    AFS      2019.0  7.431230e+07   \n",
      "396         21.5      None   AICC    AFS      2019.0  5.538294e+05   \n",
      "18829        0.1      None    FWS    FWS      2019.0  6.524062e+02   \n",
      "\n",
      "          Shape__Len                                           geometry  \\\n",
      "395    114664.653936  MULTIPOLYGON (((-142.51774 65.30717, -142.5177...   \n",
      "396      3618.407891  POLYGON ((-154.83734 66.71159, -154.83716 66.7...   \n",
      "18829     119.892335  POLYGON ((-97.36260 26.13111, -97.36260 26.130...   \n",
      "\n",
      "       DATE_NOT_NONE  DATE_LEN_VALID DATE_CUR_STAMP  \n",
      "395             True            True     2019-08-10  \n",
      "396             True            True     2019-08-10  \n",
      "18829           True            True     2019-08-10  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "No williams contained in matched",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 313>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    334\u001b[0m contains_williams \u001b[38;5;241m=\u001b[39m [matches\u001b[38;5;241m.\u001b[39miloc[[a_m]]\u001b[38;5;241m.\u001b[39mINCIDENT\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWilliams Flats\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m a_m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(matches\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])]\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m contains_williams:\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNo williams contained in matched\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# intersect closest day matches - ideally size one\u001b[39;00m\n\u001b[1;32m    339\u001b[0m intersd \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mException\u001b[0m: No williams contained in matched"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# activate env-feds env\n",
    "import osgeo\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import glob\n",
    "import shapely.speedups\n",
    "import warnings\n",
    "import folium\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "from shapely.geometry import Point\n",
    "from folium import plugins\n",
    "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning) \n",
    "from datetime import datetime\n",
    "from tqdm import tqdm # add in progress watch\n",
    "from matplotlib import pyplot as plt\n",
    "from osgeo import ogr\n",
    "\n",
    "# @NOTE: rename \"finalized_williams\" var to elim confusion for generalized v.\n",
    "\n",
    "# CONSTANTS\n",
    "perims_path = \"/projects/my-public-bucket/InterAgencyFirePerimeterHistory\"\n",
    "williams_final_path = '/projects/shared-buckets/gsfc_landslides/FEDSoutput-s3-conus/WesternUS/2019/Largefire/*4655*'\n",
    "usa_path = \"/projects/my-public-bucket/USAShapeFile\"\n",
    "\n",
    "# alternative reading\n",
    "files = glob.glob(\"/projects/shared-buckets/ashiklom/WesternUS/files_for_paper/*_.geojson\")\n",
    "data_all = pd.concat([gpd.read_file(file) for file in files],ignore_index=True)\n",
    "\n",
    "# @TODO: call path validity checks after f complete\n",
    "\n",
    "# if want to use extent set\n",
    "geojson_use = True\n",
    "geojson_keyword = 'WILLIAMS FLATS' # 'KINCADE' # 'WILLIAMS FLATS' \n",
    "\n",
    "default_crs = 'epsg:4326' #'epsg:9311' # universal crs for all geoms\n",
    "unit_dict = {'epsg:9311': 'metre', 'epsg:4326':'degree'}\n",
    "unit_preference = unit_dict[default_crs] # unit of choice @TODO double check plot impact\n",
    "\n",
    "use_final = False\n",
    "layer = 'perimeter'\n",
    "ascending = False # NOTE: use var as indicator for plot ordering\n",
    "date_column = 'DATE_CUR' # column corresponding to source date of perim (i.e. date for comparison against output) \n",
    "curr_dayrange = 5 # day range search; values [0,7] available, 1 recommended for 0 hour <-> 12 hour adjustments\n",
    "\n",
    "apply_Wildfire_Final_Perimeter = False # apply the NIFC label - WARNING: unreliable given inconsistency\n",
    "simplify_tolerance = 100 # user selected tolerance upper bound\n",
    "\n",
    "# FUNCTION DEFINITIONS\n",
    "\n",
    "# @TODO: FINISH CHECK -add s3 path/validity check w boto3\n",
    "def path_exists(path, ptype):\n",
    "    \"\"\" Check if path exists (regular OS or s3)\n",
    "            path == url to check\n",
    "            ptype == \"reg\" vs \"s3\"\n",
    "        return: boolean\n",
    "    \"\"\"\n",
    "    \n",
    "    if ptype == 's3':\n",
    "        # @TODO: fix s3 check (unable to load in)\n",
    "        s3 = boto3.resource('s3')\n",
    "\n",
    "        try:\n",
    "            s3.Object(directory, object_file).load()\n",
    "            return True \n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            if e.response['Error']['Code'] == \"404\":\n",
    "                # The object does not exist.\n",
    "                assert -1 == 0, \"Failed s3 reading, object DNE\"\n",
    "                return False\n",
    "            else:\n",
    "                assert -1 == 0, \"Failed s3 reading, non 404.\"\n",
    "                return False\n",
    "    else:\n",
    "        # @TODO: run regular os check\n",
    "        return False\n",
    "\n",
    "def get_nearest(dataset, timestamp, dayrange):\n",
    "    \"\"\" Identify rows of dataset with timestamp matches;\n",
    "        expects year, month, date in datetime format\n",
    "            dataset: input dataset to search for closest match\n",
    "            timestamp: timestamp we want a close match for\n",
    "        returns: dataset with d->m->y closest matches\n",
    "        \n",
    "        for manual intervention\n",
    "        INCIDENT.item() == 'Williams Flats'\n",
    "    \"\"\"\n",
    "    assert dayrange < 8, \"Excessive provided day range; select smaller search period.\"\n",
    "    \n",
    "    timestamp = timestamp.item()\n",
    "    # @NOTE: DATE_CUR_STAMP shouldnt be exclusive to interagency perims\n",
    "    transformed = dataset.DATE_CUR_STAMP.tolist()\n",
    "\n",
    "    clos_dict = {\n",
    "      abs(timestamp.timestamp() - date.timestamp()) : date\n",
    "      for date in transformed\n",
    "    }\n",
    "    \n",
    "    print('VERBOSE: print find_nearest variables:')\n",
    "    dataset_with_will = dataset[dataset.INCIDENT == 'Williams Flats']\n",
    "    assert not dataset_with_will.empty, \"dataset without modification has no williams flats\"\n",
    "    # print('clos_dict:')\n",
    "    # print(clos_dict)\n",
    "    print('date value of william')\n",
    "    print(dataset_with_will.iloc[[0]].DATE_CUR_STAMP.item())\n",
    "\n",
    "    res = clos_dict[min(clos_dict.keys())]\n",
    "    # print(\"Nearest date: \" + str(res))\n",
    "    \n",
    "    print('best value matches/mins by distance')\n",
    "    print(res)\n",
    "    \n",
    "    # check on dayrange flexibility\n",
    "    if abs(timestamp.day - res.day) > dayrange and dayrange == 7:\n",
    "        # trigger exception\n",
    "        return None\n",
    "    \n",
    "    assert abs(timestamp.day - res.day) <= dayrange, \"No dates found in specified range; try a more flexible range by adjusting `dayrange` var\"\n",
    "    \n",
    "    # fetch rows with res timestamp\n",
    "    finalized = dataset[dataset['DATE_CUR_STAMP'] == res]\n",
    "    \n",
    "    print('finalized set from min res')\n",
    "    print(finalized)\n",
    "    \n",
    "    return finalized\n",
    "\n",
    "# @TODO: implement recursive function on \n",
    "def best_simplification(feds, nifc, top_performance, top_tolerance, base_tolerance):\n",
    "    if base_tolerance == 0:\n",
    "        return top_tolerance\n",
    "    \n",
    "    # reduce for recursive case\n",
    "    base_tolerance -= 1\n",
    "    return best_simplification(feds, nifc, top_performance, top_tolerance, base_tolerance)\n",
    "\n",
    "# @TODO: implement error calculation relative to FEDS output\n",
    "def error_calc_feds():\n",
    "    return None\n",
    "\n",
    "# @TODO: implement error calculation relative to outside source (nifc)\n",
    "def error_calc_nifc():\n",
    "    return None\n",
    "\n",
    "# MAIN CODE \n",
    "\n",
    "# change the global options that Geopandas inherits from\n",
    "# gpd method (comp. slower)\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "# read nifc perims + us\n",
    "df = gpd.read_file(perims_path)\n",
    "usa = gpd.read_file(usa_path)\n",
    "\n",
    "# basic filtering\n",
    "# remove none geometry \n",
    "non_empty = df[df.geometry != None]\n",
    "# remove null acres\n",
    "non_null = non_empty[non_empty.GIS_ACRES != 0]\n",
    "finalized_perims = non_null\n",
    "# NOTE: filtering by 'final' label established by NIFC is UNRELIABLE!\n",
    "if apply_Wildfire_Final_Perimeter:\n",
    "    print(f'WARNING: {apply_Wildfire_Final_Perimeter} is true; may severely limit search results.')\n",
    "    finalized_perims = non_empty[non_empty.FEATURE_CA == 'Wildfire Final Perimeter']\n",
    "\n",
    "if geojson_use:\n",
    "    # check selected key in list\n",
    "    all_names = data_all['Name'].tolist()\n",
    "    assert geojson_keyword in all_names, \"Selected geojson_keyword not in GeoJson, check constants.\"\n",
    "    # read geojson\n",
    "    gdf = data_all[data_all['Name']==geojson_keyword].copy()\n",
    "    gdf = gdf.sort_values(by='t',ascending=ascending)\n",
    "else: \n",
    "    # Williams ID based path\n",
    "    lf_files = glob.glob(williams_final_path)\n",
    "    # unique lf ids if more than one, but works with only one too!\n",
    "    lf_ids = list(set([file.split('Largefire/')[1].split('_')[0] for file in lf_files])) \n",
    "    print('Number of LF ids:',len(lf_ids)) # Should be one, just william's flats\n",
    "\n",
    "    # save set of fire(s) into single var depending on mode\n",
    "\n",
    "    print('VERBOSE: print lf_ids')\n",
    "    print(lf_ids)\n",
    "    print('LAST ELEMENT OF LIST')\n",
    "    print(lf_ids[-1])\n",
    "    print('BUG: returning empty list... fire doesnt seem to exist...')\n",
    "\n",
    "    # temporary check\n",
    "    assert len(lf_ids) != 0, \"lf_ids is empty, halt algorithm.\"\n",
    "\n",
    "    # extract latest entry by ID\n",
    "    largefire_dict = dict.fromkeys(lf_ids)\n",
    "\n",
    "    for lf_id in lf_ids:\n",
    "        most_recent_file = [file for file in lf_files if lf_id in file][-1]\n",
    "        largefire_dict[lf_id] = most_recent_file\n",
    "\n",
    "    gdf = gpd.read_file(largefire_dict[lf_id],layer=layer)\n",
    "    # sort by descending time (latest to newest)\n",
    "    gdf = gdf.sort_values(by='t',ascending=ascending)\n",
    "\n",
    "if use_final:\n",
    "    print('BENCHMARKING: FINAL PERIM V. MODE')\n",
    "    # read perimeter of existing line\n",
    "    fid = lf_ids[0]\n",
    "    max_timestamp = gdf.t.max()\n",
    "    gdf = gdf[gdf.t == max_timestamp]\n",
    "    # rename for convennience\n",
    "    finalized_williams = gdf.iloc[[0]]\n",
    "    assert finalized_williams.shape[0] == 1, \"Somethings wrong, multiple perims detected...\"\n",
    "    # extract year for filtering\n",
    "    extracted_year = max_timestamp.year\n",
    "    \n",
    "    \n",
    "else:\n",
    "    # @TODO: YEAR CHECK\n",
    "    print('BENCHMARKING: EVOLVING FIRE PERIM V. MODE')\n",
    "    mul_years = False\n",
    "    finalized_williams = gdf \n",
    "    # check year uniformity\n",
    "    sample_year = finalized_williams.iloc[[0]].t.max().year\n",
    "    year_matching = [sample_year ==  finalized_williams.iloc[[j]].t.max().year for j in range(finalized_williams.shape[0])]\n",
    "    # if there was any mismatch, flag for difference\n",
    "    if False in year_matching:\n",
    "        print('WARNING: Current LargeFire contains 2+ years; NIFC filtering impacted.')\n",
    "        mul_years = True\n",
    "        # start edge case\n",
    "        # @TODO: update handling of edge case for filtering\n",
    "        # print(f'all picked up timestamps: {finalized_williams.t.tolist()}')\n",
    "        # iterate and print years for mismatch\n",
    "        for l in range(finalized_williams.shape[0]):\n",
    "            year_fetch = finalized_williams.iloc[[l]].t.item().year\n",
    "            if year_fetch != sample_year:\n",
    "                print(f'failed year: sample was {sample_year} while {year_fetch} was detected.')\n",
    "            \n",
    "        assert not mul_years, \"@TODO: catch edge case for years; force halt for now.\"\n",
    "\n",
    "# print('VERBOSE: DEBUGGING MODE')\n",
    "# print('full set of gdf')\n",
    "# print(finalized_williams)\n",
    "# print('t of full gdf')\n",
    "# print(finalized_williams.t.tolist())\n",
    "\n",
    "        \n",
    "# adjust CRS - nifc\n",
    "# default_crs\n",
    "try:\n",
    "    print('Attempting set_crs (nifc)...')\n",
    "    finalized_perims.set_crs(default_crs)\n",
    "except: \n",
    "    print('Failure: attempting to_crs application')\n",
    "    finalized_perims = finalized_perims.to_crs(default_crs)\n",
    "    print(finalized_perims.crs)\n",
    "\n",
    "# adjust FEDS crs \n",
    "try:\n",
    "    print('Attempting set_crs (FEDS)...')\n",
    "    finalized_williams.set_crs(default_crs)\n",
    "except: \n",
    "    print('Failure: attempting to_crs application')\n",
    "    finalized_williams = finalized_williams.to_crs(default_crs)\n",
    "    print(finalized_williams.crs)\n",
    "\n",
    "# unit/crs check\n",
    "assert finalized_williams.crs == finalized_perims.crs, \"CRS mismatch\"\n",
    "assert finalized_williams.crs.axis_info[0].unit_name == unit_preference, f\"finalized_williams fails unit check for: {unit_preference}, current units: {finalized_williams.crs.axis_info[0].unit_name}\"\n",
    "assert finalized_perims.crs.axis_info[0].unit_name == unit_preference, f\"finalized_perims fails unit check for: {unit_preference}\"\n",
    "\n",
    "# filter by year if year available\n",
    "try:\n",
    "    extracted_year\n",
    "    year_perims = finalized_perims[finalized_perims.FIRE_YEAR == str(extracted_year)]\n",
    "except NameError:\n",
    "    print('WARNING: No year extracted from FEDS output. Setting to None. No year reduction applied.')\n",
    "    extracted_year = None \n",
    "    year_perims = finalized_perims\n",
    "\n",
    "# root out none types\n",
    "print('VERBOSE DEBUG: DATE NOT NONE PRINT')\n",
    "print(year_perims.apply(lambda row : row.DATE_CUR is not None, axis = 1))\n",
    "\n",
    "year_perims['DATE_NOT_NONE'] = year_perims.apply(lambda row : row.DATE_CUR is not None, axis = 1)\n",
    "year_perims = year_perims[year_perims.DATE_NOT_NONE == True]\n",
    "\n",
    "# root out long-len date instances\n",
    "# @TODO: origin of these dates? just wrong user control? way to salvage them reliably?\n",
    "try:\n",
    "    year_perims['DATE_LEN_VALID'] = year_perims.apply(lambda row : len(row.DATE_CUR) == 8 , axis = 1)\n",
    "    year_perims = year_perims[year_perims.DATE_LEN_VALID == True]\n",
    "except TypeError as e: \n",
    "    # if none detected, missed by filtering - check non existence\n",
    "    print('Invalid type passed for lenght validation; check for Nones in set')\n",
    "    \n",
    "\n",
    "# transform NIFC str to new datetime object\n",
    "cur_format = '%Y%m%d' \n",
    "year_perims['DATE_CUR_STAMP'] =  year_perims.apply(lambda row : datetime.strptime(row.DATE_CUR, cur_format), axis = 1)\n",
    "\n",
    "# nifc-perim pairs as tuples\n",
    "# i.e. (perimeter FEDS instance, NIFC match)\n",
    "comparison_pairs = []\n",
    "\n",
    "axy_exists = False\n",
    "\n",
    "# per FEDS output perim -> get best NIFC match(es) by date\n",
    "print('Per FEDS output, identify best NIFC match...')\n",
    "for instance in tqdm(range(finalized_williams.shape[0])):\n",
    "    \n",
    "    # ADDED: make cumulatiev plot \n",
    "    if not axy_exists:\n",
    "        axy_exists = True\n",
    "        axy = finalized_williams.iloc[[instance]].plot(facecolor=\"orange\", edgecolor=\"black\")\n",
    "    else:\n",
    "        finalized_williams.iloc[[instance]].plot(facecolor=\"orange\", edgecolor=\"black\", ax=axy)\n",
    "        \n",
    "    # extract time stamp\n",
    "    timestamp = finalized_williams.iloc[[instance]].t\n",
    "    \n",
    "    # query matching nifc with year-month-day form\n",
    "    # year-month-day matches\n",
    "    matches = get_nearest(year_perims, timestamp, curr_dayrange)\n",
    "    \n",
    "    if matches is None:\n",
    "        # @TODO: improve handling -> likely just continue and report failed benching\n",
    "        raise Exception('FAILED: No matching dates found even with 7 day window, critical benchmarking failure.')\n",
    "        \n",
    "    # manual checker\n",
    "    contains_williams = [matches.iloc[[a_m]].INCIDENT.item()== 'Williams Flats' for a_m in range(matches.shape[0])]\n",
    "    if True not in contains_williams:\n",
    "        raise Exception('No williams contained in matched')\n",
    "        \n",
    "    # intersect closest day matches - ideally size one\n",
    "    intersd = []\n",
    "    # find all matches with intersections \n",
    "    # for a_match in matches:\n",
    "    for a_m in range(matches.shape[0]):\n",
    "    \n",
    "        # set using index\n",
    "        a_match = matches.iloc[[a_m]]\n",
    "        resulting = gpd.overlay(a_match,finalized_williams.iloc[[instance]], how='intersection')\n",
    "        \n",
    "        if a_match.INCIDENT.item() == 'Williams Flats':\n",
    "            print('VERBOSE: nifc manually ran into williams incident')\n",
    "            ax_cur = a_match.plot(facecolor=\"yellow\", edgecolor=\"black\")\n",
    "            finalized_williams.iloc[[instance]].plot(facecolor=\"red\", edgecolor=\"black\")\n",
    "        \n",
    "        \n",
    "        # added: plot results\n",
    "        ax = a_match.plot(facecolor=\"yellow\", edgecolor=\"black\", legend=True) \n",
    "        finalized_williams.iloc[[instance]].plot(facecolor=\"red\", edgecolor=\"black\", ax=ax)\n",
    "        # try: indvi plots - yellow == nifc, wiliams == red\n",
    "        a_match.plot(facecolor=\"yellow\", edgecolor=\"black\")\n",
    "        finalized_williams.iloc[[instance]].plot(facecolor=\"red\", edgecolor=\"black\")\n",
    "        \n",
    "        \n",
    "        # if non empty -> append\n",
    "        if not resulting.empty:\n",
    "            # @NOTE: do NOT append the intersection; want original object only\n",
    "            intersd.append(a_match)\n",
    "    \n",
    "    if len(intersd) == 0:\n",
    "        print(f'WARNING: Perim master row ID: {finalized_williams.iloc[[instance]].index} at index {instance} as NO INTERSECTIONS at closest date. Storing and will report 0 accuracy.')\n",
    "        comparison_pairs.append((finalized_williams.iloc[[instance]], None))\n",
    "        \n",
    "    \n",
    "    elif len(intersd) > 1:\n",
    "        # if multiple have overlay -> store them with a warning \n",
    "        print(f'NOTICE: More thane 1, in total: {len(matches)} NIFC date matches, intersect with perimeter master row ID: {finalized_williams.iloc[[instance]].index} with index in finalized_willaims: {instance}, storing all as pairs')\n",
    "        \n",
    "        # iterate and generate tuple pairs; append to list\n",
    "        [comparison_pairs.append((finalized_williams.iloc[[instance]], to_ap)) for to_ap in intersd]\n",
    "            \n",
    "    else:\n",
    "        # single match -> append (perim instance, NIFC single match)\n",
    "        comparison_pairs.append((finalized_williams.iloc[[instance]], intersd[0]))\n",
    "\n",
    "# @NOTE: consider reworking store situation - iterating over list can be time consuming for feds perims\n",
    "error_percent_performance = []\n",
    "# @TODO: store corresponding performance per single difference\n",
    "makeup_feds = []\n",
    "makeup_nifc = [] \n",
    "  \n",
    "\n",
    "# @TODO ACCURACY CALCULATION: per pair run comparison\n",
    "# calculate symmetrical difference\n",
    "for nifc_perim_pair in comparison_pairs:\n",
    "    \n",
    "    # 0: feds instance, 1: nifc matces\n",
    "    perim_inst = nifc_perim_pair[0]\n",
    "    nifc_inst = nifc_perim_pair[1]\n",
    "    \n",
    "    # if none type, append 0 accuracy and cont\n",
    "    if nifc_inst is None:\n",
    "        error_percent_performance.append(100)\n",
    "        continue\n",
    "    \n",
    "    sym_diff = perim_inst.symmetric_difference(nifc_inst, align=False)\n",
    "    \n",
    "    # use item() to fetch int out of values\n",
    "    assert sym_diff.shape[0] == 1, \"Multiple sym_diff entries identified; pair accuracy evaluation will fail.\"\n",
    "    \n",
    "    # calculate error percent: (difference / \"correct\" shape aka nifc)*100\n",
    "    error_percent = (sym_diff.geometry.area.item() / nifc_inst.geometry.area.item())*100\n",
    "    # align calculations by index -> zip n store at end\n",
    "    error_percent_performance.append(error_percent)\n",
    "\n",
    "\n",
    "\n",
    "# @NOTE: end for now just to see outputs\n",
    "print('-----------------')\n",
    "print('ANALYSIS COMPLETE')\n",
    "print('-----------------')\n",
    "\n",
    "assert len(error_percent_performance) == len(comparison_pairs), \"Mismatching dims for error performance v. comparison pairs, check resulting arrays\"\n",
    "\n",
    "print('Resulting error percentages for FEDS perimeter accuracy vs. closest intersecting NIFC:')\n",
    "count_100 = 0\n",
    "count_100_dates = []\n",
    "for index in range(len(error_percent_performance)):\n",
    "    # fetch inst + components by index\n",
    "    sam = error_percent_performance[index]\n",
    "    match_tuple = comparison_pairs[index]\n",
    "    perim_output = match_tuple[0]\n",
    "    nifc_perim = match_tuple[1]\n",
    "    \n",
    "    if sam == 100:\n",
    "        # count and append date\n",
    "        count_100 += 1\n",
    "        count_100_dates.append(perim_output.t.item())\n",
    "    else:\n",
    "        print(f'For FEDS output perimeter at {perim_output.t.item()} and NIFC perimeter at {nifc_perim.DATE_CUR_STAMP.item()}, percent error of:')\n",
    "        print(f'{sam}%')\n",
    "print(f'{count_100} instances of 100% error')\n",
    "print('FEDS output perimeter dates with no matches by threshold:')\n",
    "print(count_100_dates)\n",
    "\n",
    "# @TODO: implement proper units -> currently list w/ switch cases\n",
    "    \n",
    "# @TODO: ideal storage ideas? \n",
    "# idea: generate ipynb for visualization? \n",
    "# need to replace/write over if duplicates exist\n",
    "\n",
    "# access to alternative FEDS OUTPUT? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8667e0",
   "metadata": {},
   "source": [
    "# new code version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acd01e87",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# alternative reading\u001b[39;00m\n\u001b[1;32m     33\u001b[0m files \u001b[38;5;241m=\u001b[39m glob\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/projects/shared-buckets/ashiklom/WesternUS/files_for_paper/*_.geojson\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m data_all \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# @TODO: call path validity checks after f complete\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# if want to use extent set\u001b[39;00m\n\u001b[1;32m     39\u001b[0m geojson_use \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/env-feds/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/env-feds/lib/python3.10/site-packages/pandas/core/reshape/concat.py:347\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[1;32m    145\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    along the other axes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/env-feds/lib/python3.10/site-packages/pandas/core/reshape/concat.py:404\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    401\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 404\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# activate env-feds env\n",
    "import osgeo\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import xarray as xr\n",
    "import rasterio\n",
    "import glob\n",
    "import shapely.speedups\n",
    "import warnings\n",
    "import folium\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "from shapely.errors import ShapelyDeprecationWarning\n",
    "from shapely.geometry import Point\n",
    "from folium import plugins\n",
    "warnings.filterwarnings(\"ignore\", category=ShapelyDeprecationWarning) \n",
    "from datetime import datetime\n",
    "from tqdm import tqdm # add in progress watch\n",
    "from matplotlib import pyplot as plt\n",
    "from osgeo import ogr\n",
    "\n",
    "# @NOTE: rename \"finalized_williams\" var to elim confusion for generalized v.\n",
    "\n",
    "# CONSTANTS\n",
    "perims_path = \"/projects/my-public-bucket/InterAgencyFirePerimeterHistory\"\n",
    "williams_final_path = '/projects/shared-buckets/gsfc_landslides/FEDSoutput-s3-conus/WesternUS/2019/Largefire/*4655*'\n",
    "usa_path = \"/projects/my-public-bucket/USAShapeFile\"\n",
    "\n",
    "# alternative reading\n",
    "files = glob.glob(\"/projects/shared-buckets/ashiklom/WesternUS/files_for_paper/*_.geojson\")\n",
    "data_all = pd.concat([gpd.read_file(file) for file in files],ignore_index=True)\n",
    "\n",
    "# @TODO: call path validity checks after f complete\n",
    "\n",
    "# if want to use extent set\n",
    "geojson_use = False\n",
    "geojson_keyword = 'WILLIAMS FLATS' # 'KINCADE' # 'WILLIAMS FLATS' \n",
    "\n",
    "default_crs = 'epsg:4326' #'epsg:9311' # universal crs for all geoms\n",
    "unit_dict = {'epsg:9311': 'metre', 'epsg:4326':'degree'}\n",
    "unit_preference = unit_dict[default_crs] # unit of choice @TODO double check plot impact\n",
    "\n",
    "use_final = False\n",
    "layer = 'perimeter'\n",
    "ascending = False # NOTE: use var as indicator for plot ordering\n",
    "date_column = 'DATE_CUR' # column corresponding to source date of perim (i.e. date for comparison against output) \n",
    "curr_dayrange = 5 # day range search; values [0,7] available, 1 recommended for 0 hour <-> 12 hour adjustments\n",
    "\n",
    "apply_Wildfire_Final_Perimeter = False # apply the NIFC label - WARNING: unreliable given inconsistency\n",
    "simplify_tolerance = 100 # user selected tolerance upper bound\n",
    "\n",
    "# FUNCTION DEFINITIONS\n",
    "\n",
    "# @TODO: FINISH CHECK -add s3 path/validity check w boto3\n",
    "def path_exists(path, ptype):\n",
    "    \"\"\" Check if path exists (regular OS or s3)\n",
    "            path == url to check\n",
    "            ptype == \"reg\" vs \"s3\"\n",
    "        return: boolean\n",
    "    \"\"\"\n",
    "    \n",
    "    if ptype == 's3':\n",
    "        # @TODO: fix s3 check (unable to load in)\n",
    "        s3 = boto3.resource('s3')\n",
    "\n",
    "        try:\n",
    "            s3.Object(directory, object_file).load()\n",
    "            return True \n",
    "        except botocore.exceptions.ClientError as e:\n",
    "            if e.response['Error']['Code'] == \"404\":\n",
    "                # The object does not exist.\n",
    "                assert -1 == 0, \"Failed s3 reading, object DNE\"\n",
    "                return False\n",
    "            else:\n",
    "                assert -1 == 0, \"Failed s3 reading, non 404.\"\n",
    "                return False\n",
    "    else:\n",
    "        # @TODO: run regular os check\n",
    "        return False\n",
    "\n",
    "def get_nearest(dataset, timestamp, dayrange):\n",
    "    \"\"\" Identify rows of dataset with timestamp matches;\n",
    "        expects year, month, date in datetime format\n",
    "            dataset: input dataset to search for closest match\n",
    "            timestamp: timestamp we want a close match for\n",
    "        returns: dataset with d->m->y closest matches\n",
    "    \"\"\"\n",
    "    assert dayrange < 8, \"Excessive provided day range; select smaller search period.\"\n",
    "    \n",
    "    timestamp = timestamp.item()\n",
    "    transformed = dataset.DATE_CUR_STAMP.tolist()\n",
    "\n",
    "    clos_dict = {\n",
    "      abs(timestamp.timestamp() - date.timestamp()) : date\n",
    "      for date in transformed\n",
    "    }\n",
    "\n",
    "    res = clos_dict[min(clos_dict.keys())]\n",
    "    # print(\"Nearest date: \" + str(res))\n",
    "    \n",
    "    # check on dayrange flexibility\n",
    "    if abs(timestamp.day - res.day) > dayrange and dayrange == 7:\n",
    "        # trigger exception\n",
    "        return None\n",
    "    \n",
    "    assert abs(timestamp.day - res.day) <= dayrange, \"No dates found in specified range; try a more flexible range by adjusting `dayrange` var\"\n",
    "    \n",
    "    # fetch rows with res timestamp\n",
    "    finalized = dataset[dataset['DATE_CUR_STAMP'] == res]\n",
    "    \n",
    "    return finalized\n",
    "\n",
    "# @TODO: implement reduce/simplify geom\n",
    "def simplify_geometry(shape, tolerance):\n",
    "    # keep preserve_topology as default (true)\n",
    "    assert isinstance(shape, gpd.GeoDataFrame)\n",
    "    return shape.geometry.simplify(tolerance)\n",
    "\n",
    "# @TODO: implement recursive function on \n",
    "def best_simplification(feds, nifc, top_performance, top_tolerance, base_tolerance):\n",
    "    if base_tolerance == 0:\n",
    "        return top_tolerance\n",
    "    \n",
    "    # reduce for recursive case\n",
    "    base_tolerance -= 1\n",
    "    return best_simplification(feds, nifc, top_performance, top_tolerance, base_tolerance)\n",
    "\n",
    "# @TODO: implement error calculation relative to FEDS output\n",
    "def error_calc_feds():\n",
    "    return None\n",
    "\n",
    "# @TODO: implement error calculation relative to outside source (nifc)\n",
    "def error_calc_nifc():\n",
    "    return None\n",
    "\n",
    "# MAIN CODE \n",
    "\n",
    "# change the global options that Geopandas inherits from\n",
    "# gpd method (comp. slower)\n",
    "pd.set_option('display.max_columns',None)\n",
    "\n",
    "# read nifc perims + us\n",
    "df = gpd.read_file(perims_path)\n",
    "usa = gpd.read_file(usa_path)\n",
    "\n",
    "# basic filtering\n",
    "# remove none geometry \n",
    "non_empty = df[df.geometry != None]\n",
    "# remove null acres\n",
    "non_null = non_empty[non_empty.GIS_ACRES != 0]\n",
    "finalized_perims = non_null\n",
    "# NOTE: filtering by 'final' label established by NIFC is UNRELIABLE!\n",
    "if apply_Wildfire_Final_Perimeter:\n",
    "    print(f'WARNING: {apply_Wildfire_Final_Perimeter} is true; may severely limit search results.')\n",
    "    finalized_perims = non_empty[non_empty.FEATURE_CA == 'Wildfire Final Perimeter']\n",
    "\n",
    "if geojson_use:\n",
    "    # check selected key in list\n",
    "    all_names = data_all['Name'].tolist()\n",
    "    assert geojson_keyword in all_names, \"Selected geojson_keyword not in GeoJson, check constants.\"\n",
    "    # read geojson\n",
    "    gdf = data_all[data_all['Name']==geojson_keyword].copy()\n",
    "    gdf = gdf.sort_values(by='t',ascending=ascending)\n",
    "else: \n",
    "    # Williams ID based path\n",
    "    lf_files = glob.glob(williams_final_path)\n",
    "    # unique lf ids if more than one, but works with only one too!\n",
    "    lf_ids = list(set([file.split('Largefire/')[1].split('_')[0] for file in lf_files])) \n",
    "    print('Number of LF ids:',len(lf_ids)) # Should be one, just william's flats\n",
    "\n",
    "    # save set of fire(s) into single var depending on mode\n",
    "\n",
    "    # temporary check\n",
    "    assert len(lf_ids) != 0, \"lf_ids is empty, halt algorithm.\"\n",
    "\n",
    "    # extract latest entry by ID\n",
    "    largefire_dict = dict.fromkeys(lf_ids)\n",
    "\n",
    "    for lf_id in lf_ids:\n",
    "        most_recent_file = [file for file in lf_files if lf_id in file][-1]\n",
    "        largefire_dict[lf_id] = most_recent_file\n",
    "\n",
    "    gdf = gpd.read_file(largefire_dict[lf_id],layer=layer)\n",
    "    # sort by descending time (latest to newest)\n",
    "    gdf = gdf.sort_values(by='t',ascending=ascending)\n",
    "\n",
    "if use_final:\n",
    "    print('BENCHMARKING: FINAL PERIM V. MODE')\n",
    "    # read perimeter of existing line\n",
    "    fid = lf_ids[0]\n",
    "    max_timestamp = gdf.t.max()\n",
    "    gdf = gdf[gdf.t == max_timestamp]\n",
    "    # rename for convennience\n",
    "    finalized_williams = gdf.iloc[[0]]\n",
    "    assert finalized_williams.shape[0] == 1, \"Somethings wrong, multiple perims detected...\"\n",
    "    # extract year for filtering\n",
    "    extracted_year = max_timestamp.year\n",
    "    \n",
    "    \n",
    "else:\n",
    "    # @TODO: YEAR CHECK\n",
    "    print('BENCHMARKING: EVOLVING FIRE PERIM V. MODE')\n",
    "    mul_years = False\n",
    "    finalized_williams = gdf \n",
    "    # check year uniformity\n",
    "    sample_year = finalized_williams.iloc[[0]].t.max().year\n",
    "    year_matching = [sample_year ==  finalized_williams.iloc[[j]].t.max().year for j in range(finalized_williams.shape[0])]\n",
    "    \n",
    "    # if there was any mismatch, flag for difference (mul years)\n",
    "    if False in year_matching:\n",
    "        print('WARNING: Current LargeFire contains 2+ years; NIFC filtering impacted.')\n",
    "        mul_years = True\n",
    "        # start edge case\n",
    "        # @TODO: update handling of edge case for filtering\n",
    "        # print(f'all picked up timestamps: {finalized_williams.t.tolist()}')\n",
    "        # iterate and print years for mismatch\n",
    "        for l in range(finalized_williams.shape[0]):\n",
    "            year_fetch = finalized_williams.iloc[[l]].t.item().year\n",
    "            if year_fetch != sample_year:\n",
    "                print(f'failed year: sample was {sample_year} while {year_fetch} was detected.')\n",
    "            \n",
    "        assert not mul_years, \"@TODO: catch edge case for years; force halt for now.\"\n",
    "        \n",
    "        ax_undefined = True\n",
    "\n",
    "        for i in range(finalized_williams.shape[0]):\n",
    "            current = finalized_williams.iloc[[i]]\n",
    "            if ax_undefined:\n",
    "                ax = current.plot(facecolor=\"yellow\", edgecolor=\"black\", legend=True) \n",
    "                ax_undefined = False\n",
    "            else:\n",
    "                current.plot(facecolor=\"green\", edgecolor=\"black\", ax=ax)\n",
    "        \n",
    "    # else: single year\n",
    "    assert isinstance(sample_year, int), \"sample year fails type match\"\n",
    "    extracted_year = sample_year\n",
    "\n",
    "# print('VERBOSE: DEBUGGING MODE')\n",
    "# print('full set of gdf')\n",
    "# print(finalized_williams)\n",
    "# print('t of full gdf')\n",
    "# print(finalized_williams.t.tolist())\n",
    "ndg = True\n",
    "for gdf_try in range(gdf.shape[0]):\n",
    "    if ndg:\n",
    "        axur = gdf.iloc[[gdf_try]].plot(facecolor=\"yellow\")\n",
    "        ndg = False\n",
    "    else:\n",
    "        gdf.iloc[[gdf_try]].plot(facecolor=\"orange\",edgecolor=\"black\", ax=axur)\n",
    "\n",
    "        \n",
    "# adjust CRS - nifc\n",
    "# default_crs\n",
    "try:\n",
    "    print('Attempting set_crs (nifc)...')\n",
    "    finalized_perims.set_crs(default_crs)\n",
    "except: \n",
    "    print('Failure: attempting to_crs application')\n",
    "    finalized_perims = finalized_perims.to_crs(default_crs)\n",
    "    print(finalized_perims.crs)\n",
    "\n",
    "# adjust FEDS crs \n",
    "try:\n",
    "    print('Attempting set_crs (FEDS)...')\n",
    "    finalized_williams.set_crs(default_crs)\n",
    "except: \n",
    "    print('Failure: attempting to_crs application')\n",
    "    finalized_williams = finalized_williams.to_crs(default_crs)\n",
    "    print(finalized_williams.crs)\n",
    "    \n",
    "\n",
    "ax_undefined = True\n",
    "\n",
    "for i in range(finalized_williams.shape[0]):\n",
    "    current = finalized_williams.iloc[[i]]\n",
    "    if ax_undefined:\n",
    "        ax = current.plot(facecolor=\"yellow\", edgecolor=\"black\", legend=True) \n",
    "        ax_undefined = False\n",
    "    else:\n",
    "        current.plot(facecolor=\"blue\", edgecolor=\"black\", ax=ax)\n",
    "\n",
    "# unit/crs check\n",
    "assert finalized_williams.crs == finalized_perims.crs, \"CRS mismatch\"\n",
    "assert finalized_williams.crs.axis_info[0].unit_name == unit_preference, f\"finalized_williams fails unit check for: {unit_preference}, current units: {finalized_williams.crs.axis_info[0].unit_name}\"\n",
    "assert finalized_perims.crs.axis_info[0].unit_name == unit_preference, f\"finalized_perims fails unit check for: {unit_preference}\"\n",
    "\n",
    "# filter by year if year available\n",
    "try:\n",
    "    extracted_year\n",
    "    year_perims = finalized_perims[finalized_perims.FIRE_YEAR == str(extracted_year)]\n",
    "    \n",
    "    ax_undefined = True\n",
    "    for i in range(finalized_williams.shape[0]):\n",
    "        current = finalized_williams.iloc[[i]]\n",
    "        if ax_undefined:\n",
    "            ax = current.plot(facecolor=\"red\", edgecolor=\"black\", legend=True) \n",
    "            ax_undefined = False\n",
    "        else:\n",
    "            current.plot(facecolor=\"red\", edgecolor=\"black\", ax=ax)\n",
    "    \n",
    "except NameError:\n",
    "    print('WARNING: No year extracted from FEDS output. Setting to None. No year reduction applied.')\n",
    "    extracted_year = None \n",
    "    year_perims = finalized_perims\n",
    "    assert 1==0, \"force stop -> make algorithm rely on year? otherwise doesnt seem efficient\"\n",
    "\n",
    "# root out none types\n",
    "year_perims['DATE_NOT_NONE'] = year_perims.apply(lambda row : row.DATE_CUR is not None, axis = 1)\n",
    "year_perims = year_perims[year_perims.DATE_NOT_NONE == True]\n",
    "\n",
    "# root out long-len date instances\n",
    "# @TODO: origin of these dates? just wrong user control? way to salvage them reliably?\n",
    "try:\n",
    "    year_perims['DATE_LEN_VALID'] = year_perims.apply(lambda row : len(row.DATE_CUR) == 8 , axis = 1)\n",
    "    year_perims = year_perims[year_perims.DATE_LEN_VALID == True]\n",
    "except TypeError as e: \n",
    "    # if none detected, missed by filtering - check non existence\n",
    "    print('Invalid type passed for lenght validation; check for Nones in set')\n",
    "\n",
    "# transform NIFC str to new datetime object\n",
    "cur_format = '%Y%m%d' \n",
    "year_perims['DATE_CUR_STAMP'] =  year_perims.apply(lambda row : datetime.strptime(row.DATE_CUR, cur_format), axis = 1)\n",
    "\n",
    "# nifc-perim pairs as tuples\n",
    "# i.e. (perimeter FEDS instance, NIFC match)\n",
    "comparison_pairs = []\n",
    "\n",
    "# per FEDS output perim -> get best NIFC match(es) by date\n",
    "print('Per FEDS output, identify best NIFC match...')\n",
    "\n",
    "undef_inst_ax = True\n",
    "ax_undefined = True\n",
    "\n",
    "for i in range(finalized_williams.shape[0]):\n",
    "    current = finalized_williams.iloc[[i]]\n",
    "    if ax_undefined:\n",
    "        ax = current.plot(facecolor=\"yellow\", edgecolor=\"black\", legend=True) \n",
    "        ax_undefined = False\n",
    "    else:\n",
    "        current.plot(facecolor=\"purple\", edgecolor=\"black\", ax=ax)\n",
    "\n",
    "for instance in tqdm(range(finalized_williams.shape[0]-50)):\n",
    "    # plot cumaltive\n",
    "    if undef_inst_ax:\n",
    "        axty = finalized_williams.iloc[[instance]].plot(facecolor=\"yellow\", edgecolor=\"black\")\n",
    "        undef_inst_ax = False\n",
    "    else:\n",
    "        finalized_williams.iloc[[instance]].plot(facecolor=\"red\", edgecolor=\"black\", ax=axty)\n",
    "    \n",
    "    \n",
    "    # @TODO: run intersection first with all year_perims\n",
    "    # @TODO: store all non-zero intersections -> get nearest time stamp set (?)\n",
    "    # dont want to eliminate all matches that are one day apart\n",
    "    \n",
    "    # collection of indices relative to year_perims\n",
    "    insc_indices = []\n",
    "    # master matches with intersections/timestemp filtering\n",
    "    intersd = []\n",
    "    \n",
    "    # iterate on all year_perims and inersect\n",
    "    for insc in range(year_perims.shape[0]):\n",
    "        # fetch nifc instance\n",
    "        curr_nifc = year_perims.iloc[[insc]]\n",
    "        intersect = gpd.overlay(curr_nifc,finalized_williams.iloc[[instance]], how='intersection')\n",
    "        # cont if empty\n",
    "        if not intersect.empty:\n",
    "            insc_indices.append(insc)\n",
    "        # else: continue\n",
    "    \n",
    "    if len(insc_indices) == 0:\n",
    "        print('WARNING: insc_indices was none -> skipping step')\n",
    "        continue\n",
    "    \n",
    "    # all current indices present get_nearest check opportunities\n",
    "    # @TODO: change the get_nearest to apply for month...?\n",
    "    timestamp = finalized_williams.iloc[[instance]].t\n",
    "    # apply insc_indices to pick out intersect matches\n",
    "    reduced = year_perims.take(insc_indices)\n",
    "    # match run with get nearest\n",
    "    # although its really picky -> try for now\n",
    "    \n",
    "    # print(f'VERBOSE: reduced: {reduced}, timestamp: {timestamp}')\n",
    "    try:\n",
    "        matches = get_nearest(reduced, timestamp, curr_dayrange)\n",
    "    except:\n",
    "        # print('WARNING get_nearest failed: continue in instance comparison')\n",
    "        # indicates no match in given range -> append to failure list \n",
    "        print(f'WARNING: Perim master row ID: {finalized_williams.iloc[[instance]].index} at index {instance} as NO INTERSECTIONS at closest date. Storing and will report 0 accuracy.')\n",
    "        comparison_pairs.append((finalized_williams.iloc[[instance]], None))\n",
    "        continue\n",
    "        \n",
    "    # all matches should act as intersd -> extract from DF\n",
    "    if matches is None:\n",
    "        # @TODO: improve handling -> likely just continue and report failed benching\n",
    "        raise Exception('FAILED: No matching dates found even with 7 day window, critical benchmarking failure.')\n",
    "        \n",
    "    intersd = [matches.iloc[[ing]] for ing in range(matches.shape[0])]\n",
    "    \n",
    "    # --------\n",
    "    \n",
    "    \"\"\"\n",
    "    # extract time stamp\n",
    "    timestamp = finalized_williams.iloc[[instance]].t\n",
    "    \n",
    "    # query matching nifc with year-month-day form\n",
    "    # year-month-day matches\n",
    "    matches = get_nearest(year_perims, timestamp, curr_dayrange)\n",
    "    \"\"\"\n",
    "    \n",
    "    if matches is None:\n",
    "        # @TODO: improve handling -> likely just continue and report failed benching\n",
    "        raise Exception('FAILED: No matching dates found even with 7 day window, critical benchmarking failure.')\n",
    "        \n",
    "    # intersect closest day matches - ideally size one\n",
    "    \"\"\"\n",
    "    intersd = []\n",
    "    # find all matches with intersections \n",
    "    # for a_match in matches:\n",
    "    \n",
    "    for a_m in range(matches.shape[0]):\n",
    "    \n",
    "        # set using index\n",
    "        a_match = matches.iloc[[a_m]]\n",
    "        \n",
    "        resulting = gpd.overlay(a_match,finalized_williams.iloc[[instance]], how='intersection')\n",
    "        # if non empty -> append\n",
    "        if not resulting.empty:\n",
    "            # @NOTE: do NOT append the intersection; want original object only\n",
    "            intersd.append(a_match)\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(intersd) == 0:\n",
    "        # print(f'WARNING: Perim master row ID: {finalized_williams.iloc[[instance]].index} at index {instance} as NO INTERSECTIONS at closest date. Storing and will report 0 accuracy.')\n",
    "        # comparison_pairs.append((finalized_williams.iloc[[instance]], None))\n",
    "        assert 1==0, \"case shouldn't exist, throw exception\"\n",
    "        \n",
    "    elif len(intersd) > 1:\n",
    "        # if multiple have overlay -> store them with a warning \n",
    "        print(f'NOTICE: More thane 1, in total: {len(matches)} NIFC date matches, intersect with perimeter master row ID: {finalized_williams.iloc[[instance]].index} with index in finalized_willaims: {instance}, storing all as pairs')\n",
    "        \n",
    "        # iterate and generate tuple pairs; append to list\n",
    "        [comparison_pairs.append((finalized_williams.iloc[[instance]], to_ap)) for to_ap in intersd]\n",
    "            \n",
    "    else:\n",
    "        # single match -> append (perim instance, NIFC single match)\n",
    "        comparison_pairs.append((finalized_williams.iloc[[instance]], intersd[0]))\n",
    "\n",
    "# @NOTE: consider reworking store situation - iterating over list can be time consuming for feds perims\n",
    "error_percent_performance = []\n",
    "# @TODO: store corresponding performance per single difference\n",
    "makeup_feds = []\n",
    "makeup_nifc = [] \n",
    "  \n",
    "\n",
    "# @TODO ACCURACY CALCULATION: per pair run comparison\n",
    "# calculate symmetrical difference\n",
    "for nifc_perim_pair in comparison_pairs:\n",
    "    \n",
    "    # 0: feds instance, 1: nifc matces\n",
    "    perim_inst = nifc_perim_pair[0]\n",
    "    nifc_inst = nifc_perim_pair[1]\n",
    "    \n",
    "    # if none type, append 0 accuracy and cont\n",
    "    if nifc_inst is None:\n",
    "        error_percent_performance.append(100)\n",
    "        continue\n",
    "    \n",
    "    sym_diff = perim_inst.symmetric_difference(nifc_inst, align=False)\n",
    "    \n",
    "    # use item() to fetch int out of values\n",
    "    assert sym_diff.shape[0] == 1, \"Multiple sym_diff entries identified; pair accuracy evaluation will fail.\"\n",
    "    \n",
    "    # calculate error percent: (difference / \"correct\" shape aka nifc)*100\n",
    "    error_percent = (sym_diff.geometry.area.item() / nifc_inst.geometry.area.item())*100\n",
    "    # align calculations by index -> zip n store at end\n",
    "    error_percent_performance.append(error_percent)\n",
    "\n",
    "\n",
    "\n",
    "# @NOTE: end for now just to see outputs\n",
    "print('-----------------')\n",
    "print('ANALYSIS COMPLETE')\n",
    "print('-----------------')\n",
    "\n",
    "assert len(error_percent_performance) == len(comparison_pairs), \"Mismatching dims for error performance v. comparison pairs, check resulting arrays\"\n",
    "\n",
    "print('Resulting error percentages for FEDS perimeter accuracy vs. closest intersecting NIFC:')\n",
    "count_100 = 0\n",
    "count_100_dates = []\n",
    "for index in range(len(error_percent_performance)):\n",
    "    # fetch inst + components by index\n",
    "    sam = error_percent_performance[index]\n",
    "    match_tuple = comparison_pairs[index]\n",
    "    perim_output = match_tuple[0]\n",
    "    nifc_perim = match_tuple[1]\n",
    "    \n",
    "    if sam == 100:\n",
    "        # count and append date\n",
    "        count_100 += 1\n",
    "        count_100_dates.append(perim_output.t.item())\n",
    "    else:\n",
    "        print(f'For FEDS output perimeter at {perim_output.t.item()} and NIFC perimeter at {nifc_perim.DATE_CUR_STAMP.item()}, percent error of:')\n",
    "        print(f'{sam}%')\n",
    "print(f'{count_100} instances of 100% error')\n",
    "print('FEDS output perimeter dates with no matches by threshold:')\n",
    "print(count_100_dates)\n",
    "\n",
    "# @TODO: implement proper units -> currently list w/ switch cases\n",
    "    \n",
    "# @TODO: ideal storage ideas? \n",
    "# idea: generate ipynb for visualization? \n",
    "# need to replace/write over if duplicates exist\n",
    "\n",
    "# access to alternative FEDS OUTPUT?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc787545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envs-feds",
   "language": "python",
   "name": "envs-feds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
